{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://ae.kickscrew.com/collections/nike\"\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import csv\n",
    "import time\n",
    "driver = webdriver.Chrome()  # or webdriver.Firefox() or any other WebDriver\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "search_results = driver.find_elements(By.CLASS_NAME,\"ais-Hits-item\")\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for result in search_results:\n",
    "    # Extract title, price, and image within each search result\n",
    "    title = result.find_element(By.CLASS_NAME,\"hit-image\").get_attribute(\"alt\")\n",
    "    price = result.find_element(By.CLASS_NAME,\"product-price\").text\n",
    "    image_url = result.find_element(By.CLASS_NAME,\"hit-image\").get_attribute(\"src\")\n",
    "\n",
    "    data_list.append([title, price, image_url])\n",
    "\n",
    "# Close the browser window\n",
    "driver.quit()\n",
    "\n",
    "# Save data to CSV\n",
    "csv_file_path = \"scraped_data.csv\"\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "    # Create a CSV writer object\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "\n",
    "    # Write the header row\n",
    "    csv_writer.writerow(['Title', 'Price', 'Image URL'])\n",
    "\n",
    "    # Write the data rows\n",
    "    csv_writer.writerows(data_list)\n",
    "\n",
    "print(f\"Data has been saved to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_product_title(url):\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Locate the HTML element containing the product title\n",
    "        title_element = soup.find('div', class_='agl-js-product-title')\n",
    "\n",
    "        # Extract the text content of the title element\n",
    "        if title_element:\n",
    "            product_title = title_element.text.strip()\n",
    "            return product_title\n",
    "        else:\n",
    "            return \"Title not found on the page.\"\n",
    "\n",
    "    else:\n",
    "        # Print an error message if the request was not successful\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "url = \"https://ae.kickscrew.com/collections/nike\"\n",
    "title = get_product_title(url)\n",
    "\n",
    "if title:\n",
    "    print(f\"The product title is: {title}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = urlopen(BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = BeautifulSoup(html.read(),'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs.find_all('li',class_=\"ais-Hits-item\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs.find_all('li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Use a webdriver to load the page (make sure to have the appropriate webdriver installed)\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(BASE_URL)\n",
    "\n",
    "# Get the page source after it's fully loaded\n",
    "page_source = driver.page_source\n",
    "\n",
    "# Parse the page source with BeautifulSoup\n",
    "bs = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "# Find the element\n",
    "result = bs.find(class_=\"ais-Hits-list\")\n",
    "\n",
    "# Close the webdriver\n",
    "#driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "driver.find_element(By.CLASS_NAME, 'agl-js-product-title').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.CLASS_NAME, 'hit-image').get_attribute('src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.CLASS_NAME, 'hit-image').get_attribute('alt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.CLASS_NAME, 'product-price').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = bs.find_all('div', class_='agl-js-product-title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs.get_attribute_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.CLASS_NAME, 'agl-js-product-title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_grid = driver.find_element(By.CLASS_NAME,\"ais-Hits-list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i.get_attribute('alt') for i in results_grid.find_elements(By.CLASS_NAME, 'hit-image')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i.get_attribute('src') for i in results_grid.find_elements(By.CLASS_NAME, 'hit-image')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i.text for i in results_grid.find_elements(By.CLASS_NAME, 'product-price')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during pagination: Message: stale element reference: element is not attached to the page document\n",
      "  (Session info: chrome=103.0.5060.134); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\n",
      "Stacktrace:\n",
      "#0 0x5557151f3cd3 <unknown>\n",
      "#1 0x555714ffb968 <unknown>\n",
      "#2 0x555714ffe7c7 <unknown>\n",
      "#3 0x555714ffe66b <unknown>\n",
      "#4 0x555714ffe92c <unknown>\n",
      "#5 0x555715032cfe <unknown>\n",
      "#6 0x5557150331a1 <unknown>\n",
      "#7 0x555715027b07 <unknown>\n",
      "#8 0x555715050bdd <unknown>\n",
      "#9 0x555715027a43 <unknown>\n",
      "#10 0x555715050cbe <unknown>\n",
      "#11 0x555715063ea8 <unknown>\n",
      "#12 0x555715050aa3 <unknown>\n",
      "#13 0x5557150263fa <unknown>\n",
      "#14 0x555715027555 <unknown>\n",
      "#15 0x55571523b2bd <unknown>\n",
      "#16 0x55571523f418 <unknown>\n",
      "#17 0x55571522536e <unknown>\n",
      "#18 0x555715240078 <unknown>\n",
      "#19 0x555715219bb0 <unknown>\n",
      "#20 0x55571525cd58 <unknown>\n",
      "#21 0x55571525ced8 <unknown>\n",
      "#22 0x555715276cfd <unknown>\n",
      "#23 0x7fbab6462609 <unknown>\n",
      "\n",
      "Data has been saved to scraped_data.csv\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "def scrape_search_results(driver):\n",
    "    search_results = driver.find_elements(By.CLASS_NAME, \"ais-Hits-item\")\n",
    "\n",
    "    data_list = []\n",
    "\n",
    "    for result in search_results:\n",
    "        title = result.find_element(By.CLASS_NAME,\"hit-image\").get_attribute(\"alt\")\n",
    "        price = result.find_element(By.CLASS_NAME,\"product-price\").text\n",
    "        image_url = result.find_element(By.CLASS_NAME,\"hit-image\").get_attribute(\"src\")\n",
    "\n",
    "        data_list.append([title, price, image_url])\n",
    "\n",
    "    return data_list\n",
    "\n",
    "url = \"https://ae.kickscrew.com/collections/nike\"\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "# Introduce a sleep to allow the page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Use WebDriverWait to wait for the presence of the first result\n",
    "wait = WebDriverWait(driver, 10)\n",
    "wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"ais-Hits-item\")))\n",
    "\n",
    "# Scrape data from the first page\n",
    "all_data = scrape_search_results(driver)\n",
    "\n",
    "# Check for pagination and navigate through pages\n",
    "while True:\n",
    "    try:\n",
    "        # Look for the \"Next Page\" link\n",
    "        next_link = driver.find_element(By.CSS_SELECTOR, \".ais-Pagination-item--nextPage\")\n",
    "\n",
    "        if \"ais-Pagination-item--disabled\" in next_link.get_attribute(\"class\"):\n",
    "            print(\"No more pages. Breaking out of the loop.\")\n",
    "            break  # Break out of the loop if the link is disabled\n",
    "\n",
    "        # Click the \"Next Page\" link\n",
    "        next_link.click()\n",
    "\n",
    "        # Wait for the next page to load\n",
    "        wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"ais-Hits-item\")))\n",
    "\n",
    "        # Scrape data from the current page and append it to the existing data\n",
    "        current_data = scrape_search_results(driver)\n",
    "        all_data.extend(current_data)\n",
    "\n",
    "        # Introduce a short sleep to avoid overwhelming the server with requests\n",
    "        time.sleep(2)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during pagination: {e}\")\n",
    "        break  # Break out of the loop if there's an issue or if there's no \"Next Page\" button\n",
    "\n",
    "# Close the browser window\n",
    "driver.quit()\n",
    "\n",
    "# Save data to CSV\n",
    "csv_file_path = \"scraped_data.csv\"\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(['Title', 'Price', 'Image URL'])\n",
    "    csv_writer.writerows(all_data)\n",
    "\n",
    "print(f\"Data has been saved to {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42f79d4b816a607076411f3afae9968fab9f0ac83a9e2dbd43b0a0dcb526ff7a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
